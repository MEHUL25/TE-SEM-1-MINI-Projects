{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Detecting Covid-19 with Chest X-Ray using Pytorch\nImage classification of Chest X_rays in one of the three choices : Normal, Viral Pneumonia, COVID-19","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport shutil\nimport random\nimport torch\nimport torchvision\nimport numpy as np\nfrom distutils.dir_util import copy_tree\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(0)\n\nprint('Using Pytorch version', torch.__version__)\n\nos.mkdir(\"/kaggle/temp\")\nos.mkdir(\"/kaggle/temp/COVID-19 Radiography Database\")\n\nfrom_dir = \"../input/covid19-radiography-database/COVID-19 Radiography Database/\"\nto_dir = \"/kaggle/temp/COVID-19 Radiography Database/\"\nshutil.rmtree(to_dir)\nshutil.copytree(from_dir, to_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Training and Test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names =['normal', 'viral', 'covid']\nroot_dir = '/kaggle/temp/COVID-19 Radiography Database'\nsource_dirs = ['NORMAL', 'Viral Pneumonia', 'COVID-19']\n\nif os.path.isdir(os.path.join(root_dir, source_dirs[1])):\n    os.mkdir(os.path.join(root_dir, 'test'))\n    \n    for i,d in enumerate(source_dirs):\n        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))\n        \n    for c in class_names:\n        os.mkdir(os.path.join(root_dir, 'test', c))\n        \n    for c in class_names:\n        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]\n        selected_images = random.sample(images, 30)\n        for image in selected_images:\n            source_path = os.path.join(root_dir, c, image)\n            target_path = os.path.join(root_dir, 'test', c, image)\n            shutil.move(source_path, target_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Custom Datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class ChestXRayDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dirs, transform):\n        def get_images(class_name):\n            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n            print(f\"Found {len(images)} {class_name} examples\")\n            return images\n        \n        self.images = {}\n        self.class_names = ['normal', 'viral', 'covid']\n        \n        for c in self.class_names:\n            self.images[c] = get_images(c)\n            \n        self.image_dirs = image_dirs\n        self.transform = transform\n        \n    def __len__(self):\n        return sum([len(self.images[c]) for c in self.class_names])\n    \n    def __getitem__(self, index):\n        class_name = random.choice(self.class_names)\n        index = index % len(self.images[class_name])\n        image_name = self.images[class_name][index]\n        image_path = os.path.join(self.image_dirs[class_name], image_name)\n        image = Image.open(image_path).convert('RGB')\n        return self.transform(image), self.class_names.index(class_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Transformations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size = (224,224)),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406],\n                                    std = [0.229, 0.224, 0.225])\n])\n\ntest_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size = (224,224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406],\n                                    std = [0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataLoader","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dirs = {\n    'normal' : '/kaggle/temp/COVID-19 Radiography Database/normal',\n    'viral' : '/kaggle/temp/COVID-19 Radiography Database/viral',\n    'covid' : '/kaggle/temp/COVID-19 Radiography Database/covid'\n}\n\ntrain_dataset = ChestXRayDataset(train_dirs, train_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dirs = {\n    'normal' : '/kaggle/temp/COVID-19 Radiography Database/test/normal',\n    'viral' : '/kaggle/temp/COVID-19 Radiography Database/test/viral',\n    'covid' : '/kaggle/temp/COVID-19 Radiography Database/test/covid'\n}\n\ntest_dataset = ChestXRayDataset(test_dirs, test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 6\n\ndl_train = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size,\n                                      shuffle = True)\n\ndl_test = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size,\n                                      shuffle = True)\n\nprint('Num of training batches', len(dl_train))\nprint(\"Num of test batches\", len(dl_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_name = train_dataset.class_names\n\ndef show_images(images, labels, preds):\n    plt.figure(figsize = (8, 4))\n    for i, image in enumerate(images):\n        plt.subplot(1, 6, i + 1, xticks = [], yticks = [])\n        image = image.numpy().transpose((1,2,0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = image * std + mean\n        plt.imshow(image)\n        \n        col = 'green' if preds[i] == labels[i] else 'red'\n        \n        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color = col)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, labels = next(iter(dl_train))\nshow_images(images, labels, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18 = torchvision.models.resnet18(pretrained = True)\nprint(resnet18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18.fc = torch.nn.Linear(in_features = 512, out_features = 3)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=3e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_preds():\n    resnet18.eval()\n    images, labels = next(iter(dl_test))\n    outputs = resnet18(images)\n    _, preds = torch.max(outputs, 1)\n    show_images(images, labels, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_preds()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(epochs):\n    print('Starting training..')\n    for e in range(0, epochs):\n        print(\"=\"*20)\n        print(f'Starting epoch {e + 1}/{epochs}')\n        print(\"=\"*20)\n        \n        train_loss = 0\n        resnet18.train()\n        \n        for train_step, (images, labels) in enumerate(dl_train):\n            optimizer.zero_grad()\n            outputs = resnet18(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            if train_step % 20 == 0:\n                print(\"Evaluating at step\", train_step)\n                acc = 0\n                val_loss = 0\n                resnet18.eval()\n                \n                for val_step, (images, labels) in enumerate(dl_test):\n                    outputs = resnet18(images)\n                    loss = loss_fn(outputs, labels)\n                    val_loss += loss.item()\n                    \n                    _,preds = torch.max(outputs, 1)\n                    acc += sum((preds == labels).numpy())\n                val_loss /= (val_step + 1)\n                acc /= len(test_dataset)\n                print(f'Val loss: {val_loss:.4f}, Acc: {acc:.4f}')\n                show_preds()\n                \n                resnet18.train()\n                if acc >= 0.95:\n                    print('Performance condition satisfied')\n                    return\n        train_loss /= (train_step + 1)\n        print(f'Training loss: {train_loss:.4f}')        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(epochs=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Result","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_preds()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}